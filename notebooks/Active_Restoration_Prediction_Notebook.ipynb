{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3340986",
   "metadata": {},
   "source": [
    "# Remote Sensing-Based Monitoring of Active Restoration in the Atlantic Rainforest: Hands-on Notebook\n",
    "\n",
    "This notebook serves as an implementation guide for identifying active restoration in the Atlantic Rainforest using remote sensing imagery and Machine Learning. Developed by Felipe Begliomini for his MRes dissertation in the AI4ER program at the University of Cambridge, it provides users with step-by-step instructions to effectively utilize calibrated models and gain valuable insights into active restoration efforts within the Atlantic Rainforest. For further information about the methodology, please refer to the accompanying report available at the GitHub repository.\n",
    "\n",
    "The notebook is  designed for usage within the Google Colaboratory environment once it offers free access to GPU resources. To access the notebook, visit the [Colab Website](https://colab.research.google.com), click on \"File,\" then select \"Open notebook,\" followed by \"GitHub.\" Copy and paste the following link: https://github.com/fnincao/reforestation-CNN.git. Once opened, navigate to \"Edit,\" then select \"Notebook settings,\" and switch the hardware accelerator to GPU. If you encounter any difficulties activating the GPU, you can refer to this [link](https://medium.com/dataman-in-ai/start-using-google-colab-free-gpu-7968acb7ef92) for further assistance.\n",
    "\n",
    "After following these instructions, run the cells and proceed as instructed.\n",
    "\n",
    "## Clone GitRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ffac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fnincao/reforestation-CNN.git "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6234d0",
   "metadata": {},
   "source": [
    "## Download Pre-trained models\n",
    "\n",
    "To apply the Machine Learning models, it's necessary to download the training checkpoints from the [Zenodo repository](https://doi.org/10.5281/zenodo.8111658). Please run the following code cells to download the files directly to the `/checkpoints folder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O reforestation-CNN/checkpoints/fusion.pth.tar \"https://zenodo.org/record/8111751/files/fusion.pth.tar?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O reforestation-CNN/checkpoints/fusion_ne.pth.tar \"https://zenodo.org/record/8111751/files/fusion_ne.pth.tar?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a33d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O reforestation-CNN/checkpoints/ndvi.pth.tar \"https://zenodo.org/record/8111751/files/ndvi.pth.tar?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O reforestation-CNN/checkpoints/ndvi_ne.pth.tar \"https://zenodo.org/record/8111751/files/ndvi_ne.pth.tar?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O reforestation-CNN/checkpoints/planet.pth.tar \"https://zenodo.org/record/8111751/files/planet.pth.tar?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a50af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O reforestation-CNN/checkpoints/planet_ne.pth.tar  \"https://zenodo.org/record/8111751/files/planet_ne.pth.tar?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2eba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd reforestation-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5433693",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e .\n",
    "!pip install retry\n",
    "!pip install geemap\n",
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff43d1",
   "metadata": {},
   "source": [
    "## Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97205bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "from src.data.tools.download_gee import GetImageChips\n",
    "from src.data.tools.rename_image import rename_chips\n",
    "from src.data.tools.extract_points import retrieve_points\n",
    "from src.data.tools.crop_image import crop_ref_img\n",
    "from src.data.tools.crop_image import crop_other_img\n",
    "from src.data.tools.run_model import segment_images, rgb_predictions, save_geotiff\n",
    "from src.data.tools import vis\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075982b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91bc21a",
   "metadata": {},
   "source": [
    "## Authenticate and Initialize GEE to use the high-volume endpoint\n",
    "\n",
    "- [high-volume endpoint](https://developers.google.com/earth-engine/cloud/highvolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncoment the next line if you need to authinticate this device\n",
    "#ee.Authenticate()\n",
    "\n",
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa89da",
   "metadata": {},
   "source": [
    "## Selection of Regions of Interest\n",
    "\n",
    "The following notebook cell was created to facilitate the selection of regions for segmentation in the models. You can interact with the map provided by clicking on the highlighted areas, which are represented by an RGB composition of the Atlantic Rainforest boundaries. By clicking on a desired point on the map, a square region with a side length of 2 km will be generated and made available for download to be applied in the models. Please note that although the latitude and longitude coordinates will be recorded in the bottom right corner of the box, no markers will be displayed on the map interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "basemap =  ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/americas\")\\\n",
    "           .filterDate('2020-06-01','2020-08-31')\\\n",
    "           .select(['R','G','B'])\\\n",
    "           .first()\n",
    "\n",
    "atlantic = ee.FeatureCollection('projects/ee-fnincao/assets/atlantic_rainfores')\n",
    "\n",
    "            \n",
    "vis = {\n",
    "    'min':0,\n",
    "    'max':3000,\n",
    "    'bands':['R', 'G', 'B'],\n",
    "    'gamma': 1.2}\n",
    "\n",
    "Map.addLayer(basemap.clip(atlantic), vis, 'Planet RGB')\n",
    "\n",
    "Map.centerObject(atlantic, 5)\n",
    "\n",
    "points = retrieve_points(Map)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the selected points into a ee.FeatureCollection\n",
    "geepoints = ee.FeatureCollection([ee.Geometry.Point(lat, lon) for lon, lat in points])\n",
    "\n",
    "geepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8215b",
   "metadata": {},
   "source": [
    "## Remote Sensing Imagery pre-processing\n",
    "\n",
    "The upcoming notebook cells are dedicated to the preprocessing of remote sensing imagery, which is a crucial step in preparing the data for application in the calibrated models. The generated images are yearly composites derived from various sensors.\n",
    "\n",
    "### Planet Image 2020 (RED / GREEN / BLUE / NEAR-INFRARED) (5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a composite from Planet basemap from 2020\n",
    "planet_image =  ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/americas\")\\\n",
    "            .filterDate('2020-01-01','2020-12-31')\\\n",
    "            .median()\\\n",
    "            .select('R','G','B','N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7295b4f",
   "metadata": {},
   "source": [
    "### Planet temporal NDVI image (2016 / 2018 / 2020) (5M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562474e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNDVI(image):\n",
    "    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n",
    "    return image.addBands(ndvi);\n",
    "\n",
    "\n",
    "# Create a composite from Planet red bands from 2016-2020\n",
    "planet_ndvi_2016 =  ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/americas\")\\\n",
    "                     .filterDate('2016-01-01', '2016-12-31')\\\n",
    "                     .select(['N','R'])\\\n",
    "                     .map(addNDVI)\\\n",
    "                     .median()\\\n",
    "                     .select('NDVI')\n",
    "\n",
    "            \n",
    "planet_ndvi_2018 =  ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/americas\")\\\n",
    "                     .filterDate('2018-01-01', '2018-12-31')\\\n",
    "                     .select(['N','R'])\\\n",
    "                     .map(addNDVI)\\\n",
    "                     .median()\\\n",
    "                     .select('NDVI')\n",
    "\n",
    "planet_ndvi_2020 = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/americas\")\\\n",
    "                    .filterDate('2020-01-01', '2020-12-31')\\\n",
    "                    .select(['N','R'])\\\n",
    "                    .map(addNDVI)\\\n",
    "                    .median()\\\n",
    "                    .select('NDVI')\n",
    "           \n",
    "mosaic_planet_ndvi = planet_ndvi_2016.addBands([planet_ndvi_2018,\n",
    "                                                planet_ndvi_2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e70dc",
   "metadata": {},
   "source": [
    "### Sentinel-1 Images (Band-C VH) (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_vh_2016 = ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "            .filterDate('2016-01-01', '2016-12-31')\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "            .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\\\n",
    "            .select('VH').median()\n",
    "\n",
    "s1_vh_2018 = ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "            .filterDate('2018-01-01', '2018-12-31')\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "            .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\\\n",
    "            .select('VH').median()\n",
    "\n",
    "s1_vh_2020 = ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "            .filterDate('2020-01-01', '2020-12-31')\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "            .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\\\n",
    "            .select('VH').median()\n",
    "\n",
    "mosaic_s1_vh = s1_vh_2016.addBands([s1_vh_2018,\n",
    "                                    s1_vh_2020])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4880d809",
   "metadata": {},
   "source": [
    "### ALOS/PALSAR-2 Images (Band-L HV) (25m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de60d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "palsar_hv_2016 = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/SAR')\\\n",
    "                  .filter(ee.Filter.date('2016-01-01', '2016-12-31'))\\\n",
    "                  .select('HV')\\\n",
    "                  .first()\n",
    "\n",
    "palsar_hv_2018 = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/SAR')\\\n",
    "                  .filter(ee.Filter.date('2018-01-01', '2018-12-31'))\\\n",
    "                  .select('HV')\\\n",
    "                  .first()\n",
    "\n",
    "palsar_hv_2020 = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/SAR')\\\n",
    "                   .filter(ee.Filter.date('2020-01-01', '2020-12-31'))\\\n",
    "                   .select('HV')\\\n",
    "                   .first()\n",
    "\n",
    "mosaic_palsar_hv = palsar_hv_2016.addBands([palsar_hv_2018,\n",
    "                                            palsar_hv_2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd9190",
   "metadata": {},
   "source": [
    "### Download the Image Chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7038ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "GetImageChips(download_image=planet_image,\n",
    "              out_resolution=5,\n",
    "              points=geepoints,\n",
    "              out_dir='../data/gee_data',\n",
    "              sulfix='_planet')\n",
    "\n",
    "GetImageChips(download_image=mosaic_planet_ndvi,\n",
    "              out_resolution=5,\n",
    "              points=geepoints,\n",
    "              out_dir='../data/gee_data',\n",
    "              sulfix='_ndvi')\n",
    "\n",
    "GetImageChips(download_image=mosaic_s1_vh,\n",
    "              out_resolution=10,\n",
    "              points=geepoints,\n",
    "              out_dir='../data/gee_data',\n",
    "              sulfix='_s1')\n",
    "\n",
    "GetImageChips(download_image=mosaic_palsar_hv,\n",
    "              out_resolution=20,\n",
    "              points=geepoints,\n",
    "              out_dir='../data/gee_data',\n",
    "              sulfix='_palsar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c1242",
   "metadata": {},
   "source": [
    "## Image Cropping\n",
    "\n",
    "The upcoming cell will perform image cropping to ensure a consistent spatial extent across all images. This process simplifies the data by aligning and standardizing the size of the images, facilitating accurate and reliable analysis using the calibrated models. By establishing a uniform spatial extent, variations in size and alignment are minimized, ensuring consistentcy to subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "crop_ref_img(path='../data/gee_data',\n",
    "             out_dir='../data/croped_data')\n",
    "\n",
    "crop_other_img(sensor = 'ndvi',\n",
    "               to_crop_path='../data/gee_data',\n",
    "               out_dir='../data/croped_data',\n",
    "               ref_path='../data/croped_data')\n",
    "\n",
    "crop_other_img(sensor='s1',\n",
    "               to_crop_path='../data/gee_data',\n",
    "               out_dir='../data/croped_data',\n",
    "               ref_path='../data/croped_data')\n",
    "\n",
    "crop_other_img(sensor='palsar',\n",
    "               to_crop_path='../data/gee_data',\n",
    "               out_dir='../data/croped_data',\n",
    "               ref_path='../data/croped_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ecd5f",
   "metadata": {},
   "source": [
    "## Visualize the Image Chips\n",
    "\n",
    "The following cell functions allow you to visualize the downloaded image chips. You have the option to view individual images or visualize all image chips with the same spatial extent together. Additionally, if you activate the `save_fig` option as `True`, you can save the images in the folder `/data/figures` for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac509b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.tools import vis\n",
    "\n",
    "# Visualize planet chips\n",
    "#vis.planet_image(tile_number=1, save_fig=True)\n",
    "\n",
    "# Visualize ndvi chips\n",
    "#vis.ndvi_image(tile_number=1, save_fig=True)\n",
    "\n",
    "# Visualize s1 chips\n",
    "#vis.s1_image(tile_number=1, save_fig=True)\n",
    "\n",
    "# Visualize Palsar chips\n",
    "#vis.palsar_image(tile_number=1, save_fig=True)\n",
    "\n",
    "# Visualize all chips\n",
    "vis.all_images(tile_number=1, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf48e32",
   "metadata": {},
   "source": [
    "## Applying Calibrated Models to Downloaded Data\n",
    "\n",
    "In the following cells, the calibrated models are applied to the downloaded data. Three different configurations based on the original U-NET architecture are proposed: U-NET RGBN, U-NET NDVI, and U-NET Fusion. Each configuration differs in the Satellite Remote Sensing (SRS) layers used as input data.\n",
    "\n",
    "### U-NET RGBN\n",
    "The U-NET RGBN configuration utilizes the 4-band Planet image (Red, Green, Blue, Near-Infrared) 2020 yearly composite as input.\n",
    "\n",
    "### U-NET NDVI\n",
    "The U-NET NDVI configuration employs the Planet NDVI temporal 3-bands.\n",
    "\n",
    "### U-NET Fusion\n",
    "The U-NET Fusion configuration introduces a novel modification to the U-NET structure, allowing for the inclusion of different SRS layers with varying spatial resolutions. In this configuration, the top level inputs the Planet NDVI image, which is then reduced in spatial resolution by half using the Max Pooling operation. At the second level, the Sentinel-1 image is concatenated, and the same procedure is repeated with the ALOS/PALSAR-2 image at the third level.\n",
    "\n",
    "The calibrated models were trained using two datasets: Region of Interest 1 (ROI 1), which comprised the whole dataset, and ROI 2, which focused on a subset of the dataset with higher-quality information polygons. The accuracy metrics for each ROI are provided below. To read more insights about the results, please refer to the accompanying report available at the GitHub repository.\n",
    "\n",
    "### Accuracy Metrics - Region of Interest 1 (ROI 1)\n",
    "The accuracy metrics for the experiment in ROI 1 are presented in Table below:\n",
    "\n",
    "| Model        | Overall Accuracy | Dice Score | Precision | Recall |\n",
    "|--------------|-----------------|------------|-----------|--------|\n",
    "| U-NET RGBN   | 0.97            | 0.23       | 0.48      | 0.25   |\n",
    "| U-NET NDVI   | 0.97            | 0.16       | 0.52      | 0.16   |\n",
    "| U-NET Fusion | 0.97            | 0.26       | 0.51      | 0.31   |\n",
    "\n",
    "### Accuracy Metrics - Region of Interest 2 (ROI 2)\n",
    "The accuracy metrics for the experiment in ROI 2 are presented in Table below:\n",
    "\n",
    "| Model        | Overall Accuracy | Dice Score | Precision | Recall |\n",
    "|--------------|-----------------|------------|-----------|--------|\n",
    "| U-NET RGBN   | 0.96            | 0.40       | 0.52      | 0.39   |\n",
    "| U-NET NDVI   | 0.95            | 0.37       | 0.47      | 0.38   |\n",
    "| U-NET Fusion | 0.96            | 0.36       | 0.54      | 0.35   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13526ffe",
   "metadata": {},
   "source": [
    "#### Apply the models Calibrated at ROI 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply the U-NET RGBN calibrated in ROI 1\n",
    "rgbn_1_preds = segment_images(model_name='rgbn', roi=1)\n",
    "\n",
    "# Apply the U-NET NDVI calibrated in ROI 1\n",
    "ndvi_1_preds = segment_images(model_name='ndvi', roi=1)\n",
    "\n",
    "# Apply the U-NET FUSION calibrated in ROI 1\n",
    "fusion_1_preds = segment_images(model_name='fusion', roi=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98478d4",
   "metadata": {},
   "source": [
    "#### Apply the models Calibrated at ROI 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply the U-NET RGBN calibrated in ROI 1\n",
    "rgbn_2_preds = segment_images(model_name='rgbn', roi=2)\n",
    "\n",
    "# Apply the U-NET NDVI calibrated in ROI 1\n",
    "ndvi_2_preds = segment_images(model_name='ndvi', roi=2)\n",
    "\n",
    "# Apply the U-NET FUSION calibrated in ROI 1\n",
    "fusion_2_preds = segment_images(model_name='fusion', roi=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4866e",
   "metadata": {},
   "source": [
    "#### Save the prediction in Geotiff format\n",
    "\n",
    "This step involves saving the predictions in GeoTIFF format at the specified folder `/data/predictions`. The GeoTIFF format allows for the inclusion of georeferencing information, enabling spatial referencing and compatibility with GIS software. By saving the predictions in this format, they can be easily shared and further analyzed or visualized using various geospatial tools and applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea45316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions from U-NET RGBN calibrated in ROI 1\n",
    "save_geotiff(pred=rgnb_1_preds, roi=1, model='rgnb')\n",
    "\n",
    "#Save predictions from U-NET RGBN calibrated in ROI 1\n",
    "save_geotiff(pred=ndvi_1_preds, roi=1, model='ndvi')\n",
    "\n",
    "#Save predictions from U-NET RGBN calibrated in ROI 1\n",
    "save_geotiff(pred=fusion_1_preds, roi=1, model='fusion')\n",
    "\n",
    "#Save predictions from U-NET RGBN calibrated in ROI 1\n",
    "save_geotiff(pred=rgbn_2_preds, roi=2, model='rgbn')\n",
    "\n",
    "#Save predictions from U-NET RGBN calibrated in ROI 1\n",
    "save_geotiff(pred=ndvi_2_preds, roi=2, model='ndvi')\n",
    "\n",
    "#Save predictions from U-NET RGBN calibrated in ROI 1\n",
    "save_geotiff(pred=fusion_2_preds, roi=2, model='fusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0e467",
   "metadata": {},
   "source": [
    "#### Save Predictions with RGB Background as PNG\n",
    "\n",
    "The predictions will be saved in PNG format at the folder `/data/predictions`. Saving the predictions in this format allows for easy sharing, analysis, and visualization of the generated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions from models calibrated in ROI 1\n",
    "rgb_predictions(preds_fusion=fusion_1_preds,\n",
    "                preds_ndvi=ndvi_1_preds,\n",
    "                preds_rgbn=rgbn_1_preds,\n",
    "                roi=1)\n",
    "\n",
    "#Save predictions from models calibrated in ROI 1\n",
    "rgb_predictions(preds_fusion=fusion_2_preds,\n",
    "                preds_ndvi=ndvi_2_preds,\n",
    "                preds_rgbn=rgbn_2_preds,\n",
    "                roi=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f71b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reforest",
   "language": "python",
   "name": "reforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
